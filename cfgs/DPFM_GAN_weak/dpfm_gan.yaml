seed_everything: 0


model:
  class_path: models.DPFM_GANTrainer
  init_args:
    num_users: 6040          # safe upper bound (train split had 4832)
    num_items: 3952          # full ML-1M item ID range
    num_genders: 2
    num_occupations: 21
    genre_dim: 19
    use_attrs: true
    use_genre: true
    loss_function: "Huber"
    target_min: 1.0
    target_max: 5.0

    # capacity (can be larger if needed, but document it)
    embed_dim: 32
    mlp_dims: [128, 64]
    dropout: 0.2
    l2_penalty: 1e-3
    learning_rate: 1e-3
    dp_microbatch_size: 64
    
    # Adversarial architecture
    adv_all_hidden_dims: [128, 64]
    
    # Adversarial training schedule
    adv_start_epoch: 3
    adv_ramp_epochs: 6
    adv_lambda_start: 0.05
    adv_lambda_end: 0.30
    adv_lambda_cap: 0.30
    adv_update_freq: 3
    
    # Privacy and regularization
    repr_dropout: 0.05

    
    noise_multiplier: 0.433  # Lower for better utility in weak-DP setting
 
    
    

    predict_file: "Adv_weak"

# Lightning execution flow flags
do_train: true
do_test: true
do_predict: false
do_validate: true  # Important for DP monitoring
do_analyze: false
